<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Object Detection</title>
<style>
  body, html { margin: 0; padding: 0; overflow: hidden; background: #000; }
  #video, #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
</style>
</head>
<body>

<video id="video" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>

<script type="module">
import * as mp from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0';

const vision = mp.ObjectDetector.createFromOptions({
  modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/object_detection/ssd_mobilenetv2/fp16/1/ssd_mobilenetv2.tflite',
  runningMode: 'VIDEO',
  maxResults: 5,
  scoreThreshold: 0.5
});

const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');

let lastDetected = "";

async function startCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
  await video.play();
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
}

async function detectLoop() {
  if (video.readyState < 2) {
    requestAnimationFrame(detectLoop);
    return;
  }

  const results = vision.detectForVideo(video, Date.now());
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  if (results.detections.length > 0) {
    const det = results.detections[0];
    const label = det.categories[0].categoryName;
    const box = det.boundingBox;

    // Smaller centered bounding box
    const boxWidth = box.width * canvas.width * 0.6;
    const boxHeight = box.height * canvas.height * 0.6;
    const centerX = box.xCenter * canvas.width - boxWidth / 2;
    const centerY = box.yCenter * canvas.height - boxHeight / 2;

    ctx.strokeStyle = 'lime';
    ctx.lineWidth = 3;
    ctx.strokeRect(centerX, centerY, boxWidth, boxHeight);

    ctx.fillStyle = 'lime';
    ctx.font = '24px Arial';
    ctx.fillText(label, centerX, centerY - 10);

    // Speak only if object changed
    if (label !== lastDetected) {
      lastDetected = label;
      const utter = new SpeechSynthesisUtterance(label);
      speechSynthesis.speak(utter);
    }
  } else {
    lastDetected = "";
  }

  requestAnimationFrame(detectLoop);
}

// Start
startCamera().then(() => detectLoop());
</script>

</body>
</html>


